{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Network using Raw+Flow+Gaze\n",
    "Using Recurrent neural network techniques, we trained our model to classify different types of activities performed by a person in a day. Our dataset was collected using a Mobile eye tracker from 10 persons.It consists of the gaze data recorded using eye camera and the scene data recorded using scene camera.We use a sampling frequency of 10 seconds for raw image and gaze data. Then, We generate the optical flow image using the raw images.\n",
    "\n",
    "We split the data into 3 parts. 7 persons for training, 2 persons for testing, 1 person for validation\n",
    "\n",
    "In this model, we use all the 3 modalities of data such as raw image, optical flow image and gaze data as input.\n",
    "\n",
    "This model achieved a hamming loss of 0.2913 and predicted 41 different patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import the required library functions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import Nadam\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.core import Reshape\n",
    "import keras.backend as K\n",
    "import datetime\n",
    "import time\n",
    "import telegram\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TelegramCallback(Callback):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(TelegramCallback, self).__init__()\n",
    "        self.user_id = config['telegram_id']\n",
    "        self.model_name = config['model_name']\n",
    "        self.bot = telegram.Bot(config['token'])\n",
    "\n",
    "    def send_message(self, text):\n",
    "        try:\n",
    "            self.bot.send_message(chat_id=self.user_id, text=text)\n",
    "        except Exception as e:\n",
    "            print('Message did not send. Error: {}.'.format(e))\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        text = 'Start training model {} | {}'.format(self.model.name, self.model_name)\n",
    "        self.send_message(text)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        text = '{} | Epoch {}.\\n'.format(self.model_name, epoch)\n",
    "        for k, v in logs.items():\n",
    "            text += '{}: {:.4f}; '.format(k, v)\n",
    "        self.send_message(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDF5_PATH = '/home/gururajaramesh/completedata_withP10.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hdf = h5py.File(HDF5_PATH, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25205, 224, 224, 3) (25205, 224, 224, 3) (25205, 60) (25205, 9)\n",
      "(4665, 224, 224, 3) (4665, 224, 224, 3) (4665, 60) (4665, 9)\n",
      "(1381, 224, 224, 3) (1381, 224, 224, 3) (1381, 60) (1381, 9)\n"
     ]
    }
   ],
   "source": [
    "train_x1 = hdf[\"train/rawImages\"]\n",
    "train_x2 = hdf[\"train/flowImages\"]\n",
    "train_x3 = hdf[\"train/gazeData\"]\n",
    "train_y = hdf[\"train/labels\"]\n",
    "\n",
    "\n",
    "test_x1 = hdf[\"test/rawImages\"]\n",
    "test_x2 = hdf[\"test/flowImages\"]\n",
    "test_x3 = hdf[\"test/gazeData\"]\n",
    "test_y = hdf[\"test/labels\"]\n",
    "\n",
    "val_x1 = hdf[\"validation/rawImages\"]\n",
    "val_x2 = hdf[\"validation/flowImages\"]\n",
    "val_x3 = hdf[\"validation/gazeData\"]\n",
    "val_y = hdf[\"validation/labels\"]\n",
    "\n",
    "print(train_x1.shape, train_x2.shape, train_x3.shape, train_y.shape)\n",
    "print(test_x1.shape, test_x2.shape, test_x3.shape, test_y.shape)\n",
    "print(val_x1.shape, val_x2.shape, val_x3.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator(set_name, batch_size):\n",
    "    \"\"\"\n",
    "    This generator returns normalized capacitive images (0..1) and the respective labels in mm.\n",
    "    \"\"\"\n",
    "    hdf = h5py.File(HDF5_PATH, \"r\")\n",
    "\n",
    "    pRawImages = hdf[set_name + \"/rawImages\"]\n",
    "    pFlowImages = hdf[set_name + \"/flowImages\"]\n",
    "    pGazeData = hdf[set_name + \"/gazeData\"]\n",
    "    pLabels = hdf[set_name + \"/labels\"]\n",
    "\n",
    "    len_train = pRawImages.shape[0]\n",
    "    \n",
    "    randomBatchOrder = list(range(len_train-timesteps))\n",
    "       \n",
    "    while True:\n",
    "        np.random.shuffle(randomBatchOrder) \n",
    "        \n",
    "        for i in range(0, (len_train // (batch_size))-1):\n",
    "            gaze = []\n",
    "            frames = []\n",
    "            flow = []\n",
    "            labels = []\n",
    "            for j in range (batch_size):\n",
    "                idx = randomBatchOrder[i*batch_size+j]\n",
    "                shuffled1 = pRawImages[idx : idx+timesteps]\n",
    "                frames.append(shuffled1)\n",
    "                shuffled2 = pFlowImages[idx : idx+timesteps]\n",
    "                flow.append(shuffled2)\n",
    "                shuffled3 = pGazeData[idx : idx+timesteps]\n",
    "                gaze.append(shuffled3)\n",
    "                shuffled4 = pLabels[idx+timesteps]\n",
    "                labels.append(shuffled4)\n",
    "\n",
    "            yield [np.array(frames).reshape(-1,timesteps,224,224,3)/256, np.array(flow).reshape(-1,timesteps,224,224,3)/256, np.array(gaze).reshape(batch_size,-1, 2)], np.array(labels).reshape(-1,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "classes = 9 \n",
    "\n",
    "#no.of.epochs\n",
    "epochs = 100 \n",
    "\n",
    "# input image dimensions\n",
    "timesteps, rows, columns, channels = 5, 224, 224, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom loss function for Multilabel Classification\n",
    "def multitask_loss(y_true, y_pred):\n",
    "    # Avoid divide by 0\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # Multi-task loss\n",
    "    return K.mean(K.sum(- y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"gl...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=32)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=200)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=9)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_95 (InputLayer)           (None, 150, 2)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_42 (LSTM)                  (None, 150, 8)       352         input_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 150, 8)       0           lstm_42[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_91 (InputLayer)           (None, 5, 224, 224,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_93 (InputLayer)           (None, 5, 224, 224,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 150, 32)      288         dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_37 (TimeDistri (None, 5, 512)       14714688    input_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_38 (TimeDistri (None, 5, 512)       14714688    input_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 5, 960)       0           dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 5, 1984)      0           time_distributed_37[0][0]        \n",
      "                                                                 time_distributed_38[0][0]        \n",
      "                                                                 reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_43 (LSTM)                  (None, 32)           258176      concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 200)          6600        lstm_43[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 200)          0           dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 100)          20100       dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 100)          0           dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 9)            909         dropout_50[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 29,715,801\n",
      "Trainable params: 286,425\n",
      "Non-trainable params: 29,429,376\n",
      "__________________________________________________________________________________________________\n",
      "RAW+FLOW+GAZE(LSTM)_v02_Adam+LR.0001+LSTM8+Drop0.3+D32+LSTM32+D200+D100+sigmoid+withSlidingWindow_20190218_202438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fd5309c3a20>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   5/1788 [..............................] - ETA: 2:02:18 - loss: 6.0862 - acc: 0.2600"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    config = tf.ConfigProto(log_device_placement = True, allow_soft_placement = True)\n",
    "    config.gpu_options.allow_growth=True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    \n",
    "    with tf.Session(config=config):\n",
    "        tf.get_default_graph()\n",
    "        \n",
    "        #first VGG16 model for Raw RGB Image \n",
    "        RGB_Image = Input(shape=(timesteps, rows, columns, channels))\n",
    "\n",
    "        cnn_base = VGG16(input_shape=(rows,columns,channels), weights=\"imagenet\", include_top=False)\n",
    "\n",
    "        cnn_out = GlobalAveragePooling2D()(cnn_base.output)\n",
    "        cnn = Model(inputs=cnn_base.input, outputs=cnn_out)\n",
    "        for layer in cnn.layers:\n",
    "            layer.trainable=False\n",
    "\n",
    "        encoded_frames1 = TimeDistributed(cnn)(RGB_Image)\n",
    "\n",
    "\n",
    "        #second VGG16 model for Optical Flow Image \n",
    "        Flow_Image = Input(shape=(timesteps, rows,columns,channels))\n",
    "        cnn_flow = VGG16(input_shape=(rows,columns,channels), weights=\"imagenet\", include_top=False)\n",
    "        cnn_out2 = GlobalAveragePooling2D()(cnn_flow.output)\n",
    "\n",
    "        cnn2 = Model(input=cnn_flow.input, output=cnn_out2)\n",
    "        for layer in cnn2.layers:\n",
    "            layer.trainable=False\n",
    "\n",
    "\n",
    "        encoded_frames2 = TimeDistributed(cnn2)(Flow_Image)\n",
    "\n",
    "        #LSTM Layer for extracting features from Gaze data\n",
    "        Gaze_Data = Input(shape=(gazeShape[1], gazeShape[2]))\n",
    "        lstm1 = LSTM(8,activation='relu', return_sequences = True)(Gaze_Data)\n",
    "        lstm1 = Dropout(0.3)(lstm1)\n",
    "        encoded_frames3 = Dense(output_dim=32, activation=\"relu\")(lstm1)\n",
    "        encoded_frames3 = Reshape((timesteps, -1))(encoded_frames3)\n",
    "\n",
    "        #Concatenate the features from the three different modalities\n",
    "        merge = concatenate([encoded_frames1, encoded_frames2, encoded_frames3])\n",
    "        \n",
    "        #Concatenated features are feed to the backend LSTM model for final activity prediction\n",
    "        encoded_sequence1 = LSTM(32)(merge)\n",
    "        hidden_layer1 = Dense(output_dim=200, activation=\"relu\")(encoded_sequence1)\n",
    "        hidden_layer1 = Dropout(0.3)(hidden_layer1)\n",
    "        hidden_layer2 = Dense(output_dim=100, activation=\"relu\")(hidden_layer1)\n",
    "        hidden_layer2 = Dropout(0.3)(hidden_layer2)\n",
    "        outputs = Dense(output_dim=classes, activation=\"sigmoid\")(hidden_layer2)\n",
    "        model = Model([RGB_Image, Flow_Image, Gaze_Data], outputs, name ='LSTM_with_1Dense')\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "        #Optimizer for the Neural Network\n",
    "        optimizer = keras.optimizers.Adam(lr = 0.0001)\n",
    "        \n",
    "        #create the tensorboard file\n",
    "        readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "        file_name = \"RAW+FLOW+GAZE(LSTM)_v02_Adam+LR.0001+LSTM8+Drop0.3+D32+LSTM32+D200+D100+sigmoid+withSlidingWindow_\" + readable_timestamp\n",
    "        print(file_name)\n",
    "        tensorboardFolder = \"/srv/share/tensorboardfiles/\" + file_name\n",
    "\n",
    "        # create callback\n",
    "        config = {\n",
    "            'token': '685289263:AAEyWyUM3QjljRZjjQVZgIqqLKVPguvj9tg',   # paste your bot token\n",
    "            'telegram_id': 752166506,                                   # paste your telegram_id\n",
    "            'model_name': file_name,\n",
    "        }\n",
    "        \n",
    "        #callback for Telegram\n",
    "        tg_callback = TelegramCallback(config)\n",
    "        \n",
    "        #callback for Tensorboard\n",
    "        tb_callback = LoggingTensorBoard(settings_str_to_log=config,\n",
    "                           log_dir=tensorboardFolder,\n",
    "                           histogram_freq=0,\n",
    "                           write_graph=True,\n",
    "                           write_images=True,\n",
    "                           update_freq='epoch'\n",
    "                          )\n",
    "        \n",
    "        #callback for Model Check Point\n",
    "        sm_callback = ModelCheckpoint(str(Path.home()) + \"/models/\"+ file_name + \".{epoch:04d}-{val_loss:.2f}.h5\",\n",
    "                            monitor='val_acc',\n",
    "                            verbose=0,\n",
    "                            save_best_only=True,\n",
    "                            save_weights_only=False\n",
    "                           )\n",
    "\n",
    "\n",
    "        #compile the model\n",
    "        model.compile(loss=multitask_loss,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=[\"accuracy\"]) \n",
    "        \n",
    "        #fit the compiled model\n",
    "        history = model.fit_generator(myGenerator(\"train\", batch_size),\n",
    "                    steps_per_epoch=len(train_x1) // batch_size,\n",
    "                    epochs=epochs,callbacks = [tg_callback, tb_callback, sm_callback],\n",
    "                    verbose=1,\n",
    "                    validation_data=myGenerator(\"test\", batch_size),\n",
    "                    validation_steps=len(test_x1) // batch_size)\n",
    "        \n",
    "        #predict using the trained model with the validation data\n",
    "        result = model.predict_generator(myGenerator(\"validation\", batch_size), steps=len(val_x1) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot for Training vs Test Accuracy\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Test Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot for Training vs Test Loss\n",
    "plt.plot(history.history['val_loss'], label=\"Test Loss\")\n",
    "plt.plot(history.history['loss'], label=\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Training vs Test Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain predicted output in terms of one hot coding\n",
    "y_predict = np.copy(result)\n",
    "y_predict[y_predict>0.5]=1\n",
    "y_predict[y_predict<0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1381, 1, 9)\n",
      "(1381, 9)\n",
      "(1380, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.load('/home/gururajaramesh/P10data/LabelsP10.npy')\n",
    "print(y_true.shape)\n",
    "y_true = y_true.reshape(-1,9)\n",
    "print(y_true.shape)\n",
    "y_true1= y_true[0:1380,:]\n",
    "print(y_true1.shape)\n",
    "y_true1[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Summary of the precision, recall, F1 score for each class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        87\n",
      "           1       0.25      0.13      0.17       249\n",
      "           2       0.64      0.18      0.28       803\n",
      "           3       0.08      0.09      0.09        79\n",
      "           4       0.70      0.19      0.30       897\n",
      "           5       0.04      0.03      0.04       121\n",
      "           6       0.20      0.24      0.22       202\n",
      "           7       0.12      0.11      0.11       136\n",
      "           8       0.09      0.55      0.16       128\n",
      "\n",
      "   micro avg       0.26      0.18      0.21      2702\n",
      "   macro avg       0.24      0.17      0.15      2702\n",
      "weighted avg       0.47      0.18      0.23      2702\n",
      " samples avg       0.20      0.19      0.19      2702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "#Classfication report for the predicted output\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_true1, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hamming Loss: \n",
      "0.29138486312399353\n"
     ]
    }
   ],
   "source": [
    "#Hamming loss of the predicted output\n",
    "print ('\\n Hamming Loss: ')\n",
    "print(sklearn.metrics.hamming_loss(y_true1, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new pattern : [0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0.] pattern found 20 times\n",
      "Found new pattern : [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 1.] pattern found 45 times\n",
      "Found new pattern : [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1.] pattern found 608 times\n",
      "Found new pattern : [0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 0.] pattern found 139 times\n",
      "Found new pattern : [0. 0. 1. 0. 1. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 1.] pattern found 22 times\n",
      "Found new pattern : [0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 1.] pattern found 23 times\n",
      "Found new pattern : [1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 1. 0. 0. 0. 0. 0.] pattern found 10 times\n",
      "Found new pattern : [0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 1.] pattern found 33 times\n",
      "Found new pattern : [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0.] pattern found 53 times\n",
      "Found new pattern : [0. 0. 1. 0. 1. 1. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 1. 1. 0. 0. 1.] pattern found 2 times\n",
      "Found new pattern : [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0.] pattern found 35 times\n",
      "Found new pattern : [0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 1. 0.] pattern found 4 times\n",
      "Found new pattern : [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0.] pattern found 37 times\n",
      "Found new pattern : [0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 1. 0. 0.] pattern found 14 times\n",
      "Found new pattern : [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0.] pattern found 124 times\n",
      "Found new pattern : [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.] pattern found 34 times\n",
      "Found new pattern : [0. 0. 1. 0. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 1. 0. 0. 0.] pattern found 34 times\n",
      "Found new pattern : [0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 1. 0. 0. 0. 0.] pattern found 4 times\n",
      "Found new pattern : [0. 1. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 1. 1. 0. 0. 0.] pattern found 2 times\n",
      "Found new pattern : [0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 1.] pattern found 4 times\n",
      "Found new pattern : [0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0.] pattern found 40 times\n",
      "Found new pattern : [0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 1. 0. 0. 0. 0. 0.] pattern found 6 times\n",
      "Found new pattern : [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0.] pattern found 37 times\n",
      "Found new pattern : [0. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 1. 0. 1. 0. 0. 0. 0.] pattern found 4 times\n",
      "Found new pattern : [0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0.] pattern found 5 times\n",
      "Found new pattern : [0. 1. 1. 0. 1. 1. 0. 0. 0.]\n",
      "[0. 1. 1. 0. 1. 1. 0. 0. 0.] pattern found 2 times\n",
      "Found new pattern : [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0.] pattern found 6 times\n",
      "Found new pattern : [0. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 1. 1. 0.] pattern found 4 times\n",
      "Found new pattern : [0. 1. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 1. 0. 0. 0. 0. 1.] pattern found 2 times\n",
      "Found new pattern : [0. 0. 1. 0. 1. 0. 1. 1. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 1. 1. 0.] pattern found 2 times\n",
      "Found new pattern : [0. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 1. 0. 0.] pattern found 11 times\n",
      "Found new pattern : [0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 0.] pattern found 2 times\n",
      "Found new pattern : [0. 0. 0. 0. 1. 1. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 1.] pattern found 2 times\n",
      "Found new pattern : [1. 1. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[1. 1. 0. 1. 0. 0. 0. 0. 1.] pattern found 1 times\n",
      "Found new pattern : [0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 1.] pattern found 1 times\n",
      "Found new pattern : [0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 1.] pattern found 2 times\n",
      "Found new pattern : [0. 0. 1. 0. 1. 1. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 1. 1. 0. 1. 0.] pattern found 1 times\n",
      "Found new pattern : [0. 1. 1. 0. 1. 0. 0. 0. 1.]\n",
      "[0. 1. 1. 0. 1. 0. 0. 0. 1.] pattern found 2 times\n",
      "Found new pattern : [0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 1. 0. 0. 0. 0.] pattern found 1 times\n",
      "Found new pattern : [0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 1.] pattern found 1 times\n",
      "Found new pattern : [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0.] pattern found 1 times\n"
     ]
    }
   ],
   "source": [
    "#to find the number of different patterns in the predicted output\n",
    "y_true = np.copy(y_predict)\n",
    "firsttime = True\n",
    "patternlist = []\n",
    "countlist = []\n",
    "for i in range(y_true.shape[0]):\n",
    "    if(firsttime):\n",
    "        curr_pattern = y_true[0,:]\n",
    "        print('Found new pattern : %s' % curr_pattern)\n",
    "        patternlist.append(curr_pattern)\n",
    "        count = 0\n",
    "        for j in range(y_true.shape[0]):\n",
    "            #check if the pattern is same as the curr.pattern and increase count if not continue\n",
    "            if(np.array_equal(curr_pattern, y_true[j,:])):\n",
    "                count =  count + 1\n",
    "            else:\n",
    "                continue\n",
    "        countlist.append(count)\n",
    "        firsttime = False\n",
    "        print('%s pattern found %s times' % (curr_pattern, count))\n",
    "    else:\n",
    "        curr_pattern = y_true[i,:]\n",
    "        new_pattern = False\n",
    "        already_present= False\n",
    "        #check if curr_pattern is in patternlist\n",
    "        for k in range(len(patternlist)):\n",
    "            if(np.array_equal(curr_pattern, patternlist[k])):\n",
    "                already_present = True\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        if(already_present):\n",
    "            new_pattern = False\n",
    "        else:\n",
    "            new_pattern = True\n",
    "        #if it is a new pattern  then count its occurance    \n",
    "        if(new_pattern):\n",
    "            print('Found new pattern : %s' % curr_pattern)\n",
    "            patternlist.append(curr_pattern)\n",
    "            count = 0\n",
    "            for j in range(y_true.shape[0]):\n",
    "                if(np.array_equal(curr_pattern, y_true[j,:])):\n",
    "                    count = count + 1\n",
    "                else:\n",
    "                    continue\n",
    "            countlist.append(count)\n",
    "            print('%s pattern found %s times' % (curr_pattern, count))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the No.of Samples vs Types of patters\n",
    "x1 = list(range(len(countlist)))\n",
    "plt.bar(x1, countlist)\n",
    "plt.xlabel('Types of Patterns', fontsize=10)\n",
    "plt.ylabel('No. of Samples', fontsize=10)\n",
    "plt.title('Long Term Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the HDF5 file\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model as HDF5 file\n",
    "model.save(\"Raw+Flow+Gaze_RMSProp.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
