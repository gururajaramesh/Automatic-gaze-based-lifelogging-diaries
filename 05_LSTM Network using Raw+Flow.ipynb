{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Network using Raw+Flow\n",
    "Using Recurrent neural network techniques, we trained our model to classify different types of activities performed by a person in a day. Our dataset was collected using a Mobile eye tracker from 10 persons.It consists of the gaze data recorded using eye camera and the scene data recorded using scene camera.We use a sampling frequency of 10 seconds for raw image and gaze data. Then, We generate the optical flow image using the raw images.\n",
    "\n",
    "We split the data into 3 parts. 7 persons for training, 2 persons for testing, 1 person for validation\n",
    "\n",
    "In this model, we use two different modalities of data such as raw image and optical flow image as input.\n",
    "\n",
    "This model achieved a hamming loss of 0.2305 and predicted 9 different patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import the required library functions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import Nadam\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.core import Reshape\n",
    "import keras.backend as K\n",
    "import datetime\n",
    "import time\n",
    "import telegram\n",
    "from keras import metrics\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TelegramCallback(Callback):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(TelegramCallback, self).__init__()\n",
    "        self.user_id = config['telegram_id']\n",
    "        self.model_name = config['model_name']\n",
    "        self.bot = telegram.Bot(config['token'])\n",
    "\n",
    "    def send_message(self, text):\n",
    "        try:\n",
    "            self.bot.send_message(chat_id=self.user_id, text=text)\n",
    "        except Exception as e:\n",
    "            print('Message did not send. Error: {}.'.format(e))\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        text = 'Start training model {} | {}'.format(self.model.name, self.model_name)\n",
    "        self.send_message(text)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        text = '{} | Epoch {}.\\n'.format(self.model_name, epoch)\n",
    "        for k, v in logs.items():\n",
    "            text += '{}: {:.4f}; '.format(k, v)\n",
    "        self.send_message(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDF5_PATH = '/home/gururajaramesh/completedata_withP10.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf=h5py.File(HDF5_PATH,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17884, 224, 224, 3) (17884, 224, 224, 3) (17884, 60) (17884, 9)\n",
      "(4665, 224, 224, 3) (4665, 224, 224, 3) (4665, 60) (4665, 9)\n",
      "(1381, 224, 224, 3) (1381, 224, 224, 3) (1381, 60) (1381, 9)\n"
     ]
    }
   ],
   "source": [
    "train_x1 = hdf[\"train/rawImages\"]\n",
    "train_x2 = hdf[\"train/flowImages\"]\n",
    "train_x3 = hdf[\"train/gazeData\"]\n",
    "train_y = hdf[\"train/labels\"]\n",
    "\n",
    "\n",
    "test_x1 = hdf[\"test/rawImages\"]\n",
    "test_x2 = hdf[\"test/flowImages\"]\n",
    "test_x3 = hdf[\"test/gazeData\"]\n",
    "test_y = hdf[\"test/labels\"]\n",
    "\n",
    "val_x1 = hdf[\"validation/rawImages\"]\n",
    "val_x2 = hdf[\"validation/flowImages\"]\n",
    "val_x3 = hdf[\"validation/gazeData\"]\n",
    "val_y = hdf[\"validation/labels\"]\n",
    "\n",
    "print(train_x1.shape, train_x2.shape, train_x3.shape, train_y.shape)\n",
    "print(test_x1.shape, test_x2.shape, test_x3.shape, test_y.shape)\n",
    "print(val_x1.shape, val_x2.shape, val_x3.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator(set_name, batch_size):\n",
    "    \"\"\"\n",
    "    This generator returns normalized capacitive images (0..1) and the respective labels in mm.\n",
    "    \"\"\"\n",
    "    hdf = h5py.File(HDF5_PATH, \"r\")\n",
    "\n",
    "    pRawImages = hdf[set_name + \"/rawImages\"]\n",
    "    pFlowImages = hdf[set_name + \"/flowImages\"]\n",
    "    pLabels = hdf[set_name + \"/labels\"]\n",
    "\n",
    "    len_train = pRawImages.shape[0]\n",
    "    \n",
    "    randomBatchOrder = list(range(len_train-timesteps))\n",
    "       \n",
    "    while True:\n",
    "        np.random.shuffle(randomBatchOrder) \n",
    "        \n",
    "        for i in range(0, (len_train // (batch_size))-1):\n",
    "            frames = []\n",
    "            flow = []\n",
    "            labels = []\n",
    "            for j in range (batch_size):\n",
    "                idx = randomBatchOrder[i*batch_size+j]\n",
    "                shuffled1 = pRawImages[idx : idx+timesteps]\n",
    "                frames.append(shuffled1)\n",
    "                shuffled2 = pFlowImages[idx : idx+timesteps]\n",
    "                flow.append(shuffled2)\n",
    "                shuffled4 = pLabels[idx+timesteps]\n",
    "                labels.append(shuffled4)\n",
    "\n",
    "            yield [np.array(frames).reshape(-1,timesteps,224,224,3)/256, np.array(flow).reshape(-1,timesteps,224,224,3)/256], np.array(labels).reshape(-1,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "classes = 9 \n",
    "\n",
    "#no.of.epochs\n",
    "epochs = 150\n",
    "\n",
    "# input image dimensions\n",
    "timesteps, rows, columns, channels = 5, 224, 224, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom loss function for Multilabel Classification\n",
    "def multitask_loss(y_true, y_pred):\n",
    "    # Avoid divide by 0\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # Multi-task loss\n",
    "    return K.mean(K.sum(- y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"gl...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=200)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=9)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 5, 224, 224,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 5, 224, 224,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 5, 512)       14714688    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 5, 512)       14714688    input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 1024)      0           time_distributed_3[0][0]         \n",
      "                                                                 time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 64)           278784      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 200)          13000       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 200)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          20100       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 100)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 9)            909         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 29,742,169\n",
      "Trainable params: 312,793\n",
      "Non-trainable params: 29,429,376\n",
      "__________________________________________________________________________________________________\n",
      "RAW+FLOW_v01_Adam+LSTM8+D32+LSTM64+D200+D100+Sigmoid+NoSlidingWindow_20190207_111510\n",
      "Epoch 1/150\n",
      "357/357 [==============================] - 580s 2s/step - loss: 5.1600 - acc: 0.1064 - val_loss: 4.0825 - val_acc: 0.0925\n",
      "Epoch 2/150\n",
      "357/357 [==============================] - 590s 2s/step - loss: 4.2875 - acc: 0.1518 - val_loss: 3.8334 - val_acc: 0.1000\n",
      "Epoch 3/150\n",
      "357/357 [==============================] - 590s 2s/step - loss: 3.8515 - acc: 0.1745 - val_loss: 3.6136 - val_acc: 0.1086\n",
      "Epoch 4/150\n",
      "357/357 [==============================] - 582s 2s/step - loss: 3.5564 - acc: 0.2146 - val_loss: 3.3856 - val_acc: 0.1935\n",
      "Epoch 5/150\n",
      "146/357 [===========>..................] - ETA: 4:31 - loss: 3.4060 - acc: 0.2178"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    config = tf.ConfigProto(log_device_placement = True, allow_soft_placement = True)\n",
    "    config.gpu_options.allow_growth=True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    \n",
    "    with tf.Session(config=config):\n",
    "        tf.get_default_graph()\n",
    "        #First VGG16 model for Raw RGB Image \n",
    "        RGB_Image = Input(shape=(timesteps, rows, columns, channels))\n",
    "\n",
    "        cnn_base = VGG16(input_shape=(rows,columns,channels), weights=\"imagenet\", include_top=False)\n",
    "\n",
    "        cnn_out = GlobalAveragePooling2D()(cnn_base.output)\n",
    "        cnn = Model(inputs=cnn_base.input, outputs=cnn_out)\n",
    "        for layer in cnn.layers:\n",
    "            layer.trainable=False\n",
    "\n",
    "        encoded_frames1 = TimeDistributed(cnn)(RGB_Image)\n",
    "\n",
    "\n",
    "        #second VGG16 model for Optical Flow Image \n",
    "        Flow_Image = Input(shape=(timesteps, rows,columns,channels))\n",
    "        cnn_flow = VGG16(input_shape=(rows,columns,channels), weights=\"imagenet\", include_top=False)\n",
    "        cnn_out2 = GlobalAveragePooling2D()(cnn_flow.output)\n",
    "\n",
    "        cnn2 = Model(input=cnn_flow.input, output=cnn_out2)\n",
    "        for layer in cnn2.layers:\n",
    "            layer.trainable=False\n",
    "\n",
    "        encoded_frames2 = TimeDistributed(cnn2)(Flow_Image)\n",
    "\n",
    "        #Concatenate the features from the two different modalities\n",
    "        merge = concatenate([encoded_frames1, encoded_frames2])\n",
    "\n",
    "        #Concatenated features are feed to the backend LSTM model for final activity prediction\n",
    "        encoded_sequence = LSTM(64)(merge)\n",
    "        encoded_sequence = Dropout(0.3)(encoded_sequence)\n",
    "        hidden_layer1 = Dense(output_dim=200, activation=\"relu\")(encoded_sequence)\n",
    "        hidden_layer1 = Dropout(0.5)(hidden_layer1)\n",
    "        hidden_layer2 = Dense(output_dim=100, activation=\"relu\")(hidden_layer1)\n",
    "        hidden_layer2 = Dropout(0.5)(hidden_layer2)\n",
    "        outputs = Dense(output_dim=classes, activation=\"sigmoid\")(hidden_layer2)\n",
    "        model = Model([RGB_Image, Flow_Image], outputs, name ='RAW+FLOW_v01_Adam+LSTM8+D32+LSTM64+D100+Sigmoid')\n",
    "        model.summary()\n",
    "\n",
    "        #Optimizer for the Neural Network\n",
    "        optimizer = keras.optimizers.Adam(lr=0.0001)\n",
    "        \n",
    "        #create the tensorboard file\n",
    "        readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "        file_name = \"RAW+FLOW_v01_Adam+LSTM8+D32+LSTM64+D200+D100+Sigmoid+NoSlidingWindow_\" + readable_timestamp\n",
    "        print(file_name)\n",
    "        tensorboardFolder = \"/home/gururajaramesh/tensorboardfiles/\" + file_name\n",
    "        \n",
    "        # create callback\n",
    "        config = {\n",
    "            'token': '751130989:AAGKiP8ibYbR6CoXHz6eXE8mR2vcYO57dwM',   # paste your bot token\n",
    "            'telegram_id': 752166506,                                   # paste your telegram_id\n",
    "            'model_name': file_name,\n",
    "        }\n",
    "\n",
    "        #callback for Telegram\n",
    "        tg_callback = TelegramCallback(config)\n",
    "        \n",
    "        #callback for Tensorboard\n",
    "        tb_callback = LoggingTensorBoard(settings_str_to_log=config,\n",
    "                           log_dir=tensorboardFolder,\n",
    "                           histogram_freq=0,\n",
    "                           write_graph=True,\n",
    "                           write_images=True,\n",
    "                           update_freq='epoch'\n",
    "                          )\n",
    "        \n",
    "        #callback for Model Check Point\n",
    "        sm_callback = ModelCheckpoint(str(Path.home()) + \"/models/\"+ file_name + \".{epoch:04d}-{val_loss:.2f}.h5\",\n",
    "                            monitor='val_acc',\n",
    "                            verbose=0,\n",
    "                            save_best_only=True,\n",
    "                            save_weights_only=False\n",
    "                           )\n",
    "        \n",
    "        #compile the model\n",
    "        model.compile(loss=multitask_loss,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=[\"acc\"]) \n",
    "\n",
    "        #fit the compiled model\n",
    "        history = model.fit_generator(myGenerator(\"train\", batch_size),\n",
    "                    steps_per_epoch=len(train_x1) // (batch_size*timesteps),\n",
    "                    epochs=epochs,callbacks = [tg_callback, tb_callback, sm_callback],\n",
    "                    verbose=1,\n",
    "                    validation_data=myGenerator(\"test\", batch_size),\n",
    "                    validation_steps=len(test_x1) // (batch_size*timesteps))\n",
    "        \n",
    "        #predict using the trained model with the validation data\n",
    "        result = model.predict_generator(myGenerator(\"validation\", batch_size), steps=len(val_x1) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for Training vs Test Accuracy\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Test Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for Training vs Test Loss\n",
    "plt.plot(history.history['val_loss'], label=\"Test Loss\")\n",
    "plt.plot(history.history['loss'], label=\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Training vs Test Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain predicted output in terms of one hot coding\n",
    "y_predict = np.copy(result)\n",
    "y_predict[y_predict>0.5]=1\n",
    "y_predict[y_predict<0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1381, 1, 9)\n",
      "(1381, 9)\n",
      "(1380, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.load('/home/gururajaramesh/P10data/LabelsP10.npy')\n",
    "print(y_true.shape)\n",
    "y_true = y_true.reshape(-1,9)\n",
    "print(y_true.shape)\n",
    "y_true1= y_true[0:1380,:]\n",
    "print(y_true1.shape)\n",
    "y_true[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Summary of the precision, recall, F1 score for each class:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        87\n",
      "          1       0.19      0.16      0.17       249\n",
      "          2       0.54      0.26      0.35       803\n",
      "          3       0.00      0.00      0.00        79\n",
      "          4       0.62      0.33      0.43       897\n",
      "          5       0.10      0.11      0.11       121\n",
      "          6       0.11      0.01      0.02       202\n",
      "          7       0.00      0.00      0.00       136\n",
      "          8       0.07      0.03      0.04       128\n",
      "\n",
      "avg / total       0.40      0.21      0.27      2702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "#Classfication report for the predicted output\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_true1, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: \n",
      "0.23051529790660225\n"
     ]
    }
   ],
   "source": [
    "#Hamming loss of the predicted output\n",
    "print ('Hamming Loss: ')\n",
    "print(sklearn.metrics.hamming_loss(y_true1, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new pattern : [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.] pattern found 607 times\n",
      "Found new pattern : [0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 0.] pattern found 264 times\n",
      "Found new pattern : [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0.] pattern found 212 times\n",
      "Found new pattern : [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0.] pattern found 89 times\n",
      "Found new pattern : [0. 0. 1. 0. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 1. 0. 0. 0.] pattern found 121 times\n",
      "Found new pattern : [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1.] pattern found 56 times\n",
      "Found new pattern : [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0.] pattern found 7 times\n",
      "Found new pattern : [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0.] pattern found 18 times\n",
      "Found new pattern : [1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 1. 0. 0. 0. 0. 0.] pattern found 3 times\n",
      "Found new pattern : [0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0.] pattern found 3 times\n"
     ]
    }
   ],
   "source": [
    "#to find the number of different patterns in the predicted output\n",
    "y_true = np.copy(y_predict)\n",
    "firsttime = True\n",
    "patternlist = []\n",
    "countlist = []\n",
    "for i in range(y_true.shape[0]):\n",
    "    if(firsttime):\n",
    "        curr_pattern = y_true[0,:]\n",
    "        print('Found new pattern : %s' % curr_pattern)\n",
    "        patternlist.append(curr_pattern)\n",
    "        count = 0\n",
    "        for j in range(y_true.shape[0]):\n",
    "            #check if the pattern is same as the curr.pattern and increase count if not continue\n",
    "            if(np.array_equal(curr_pattern, y_true[j,:])):\n",
    "                count =  count + 1\n",
    "            else:\n",
    "                continue\n",
    "        countlist.append(count)\n",
    "        firsttime = False\n",
    "        print('%s pattern found %s times' % (curr_pattern, count))\n",
    "    else:\n",
    "        curr_pattern = y_true[i,:]\n",
    "        new_pattern = False\n",
    "        already_present= False\n",
    "        #check if curr_pattern is in patternlist\n",
    "        for k in range(len(patternlist)):\n",
    "            if(np.array_equal(curr_pattern, patternlist[k])):\n",
    "                already_present = True\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        if(already_present):\n",
    "            new_pattern = False\n",
    "        else:\n",
    "            new_pattern = True\n",
    "        #if it is a new pattern  then count its occurance    \n",
    "        if(new_pattern):\n",
    "            print('Found new pattern : %s' % curr_pattern)\n",
    "            patternlist.append(curr_pattern)\n",
    "            count = 0\n",
    "            for j in range(y_true.shape[0]):\n",
    "                if(np.array_equal(curr_pattern, y_true[j,:])):\n",
    "                    count = count + 1\n",
    "                else:\n",
    "                    continue\n",
    "            countlist.append(count)\n",
    "            print('%s pattern found %s times' % (curr_pattern, count))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the No.of Samples vs Types of patters\n",
    "x1 = list(range(len(countlist)))\n",
    "plt.bar(x1, countlist)\n",
    "plt.xlabel('Types of Patterns', fontsize=10)\n",
    "plt.ylabel('No. of Samples', fontsize=10)\n",
    "plt.title('Long Term Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the HDF5 file\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model as HDF5 file\n",
    "model.save(\"Raw+Flow_Adam.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
